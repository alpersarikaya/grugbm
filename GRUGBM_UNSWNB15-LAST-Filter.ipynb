{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REQUIRED LIBRARIES\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Flatten\n",
    "from tensorflow.keras.layers import CuDNNGRU,GRU\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "from numpy import newaxis\n",
    "from collections import Counter\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "import os\n",
    "import random\n",
    "import lightgbm as gbm\n",
    "from sklearn.metrics import mean_squared_error,roc_auc_score,precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REPRODUCABLE RESULT\n",
    "seed_value= 2020\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.set_random_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATASET LOADING\n",
    "training = pd.read_csv(\"UNSW_NB15_total_numeric_training.csv\")\n",
    "testing = pd.read_csv(\"UNSW_NB15_total_numeric_testing.csv\")\n",
    "\n",
    "WRAPPER = [\"service\",\"state\",\"sbytes\",\"dbytes\",\"sttl\",\"dttl\",\"sload\",\"sloss\",\"dloss\",\n",
    "       \"smean\",\"dmean\",\"response_body_len\",\"ct_srv_src\",\"ct_dst_sport_ltm\",\"ct_src_dport_ltm\",\"ct_dst_src_ltm\",\n",
    "       \"is_ftp_login\",\"ct_ftp_cmd\",\"ct_srv_dst\"]\n",
    "\n",
    "FILTER = [\"service\",\"sbytes\",\"sttl\",\"smean\",\"ct_dst_sport_ltm\",\"ct_src_dport_ltm\",\"proto\"]\n",
    "\n",
    "THRES = ['smean','sbytes','dmean','proto','ct_srv_dst','dbytes','ct_dst_src_ltm','service','sload',\n",
    "         'response_body_len','dur','sttl','ct_srv_src','synack','ct_src_ltm','sjit','sloss','dload','stcpb','djit',\n",
    "         'ackdat','dpkts','tcprtt','dtcpb']\n",
    "\n",
    "x_tr = training.drop([\"id\",\"label\",\"attack_cat\"],axis=1)\n",
    "x_tr = x_tr[THRES]\n",
    "y_tr = training[[\"attack_cat\"]]\n",
    "                      \n",
    "x_ts = testing.drop([\"id\",\"label\",\"attack_cat\"],axis=1)\n",
    "x_ts = x_ts[THRES]\n",
    "y_ts = testing[[\"attack_cat\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATASET DIVIDING FOR TESTING\n",
    "x_tr_p1,x_tr_p2,y_tr_p1,y_tr_p2 = train_test_split(x_tr,y_tr,test_size=0.5,stratify=y_tr,random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#LIGHTGBM FEATURE SELECTION PROCESS\n",
    "start = time()\n",
    "lgb_train = gbm.Dataset(x_tr_p1,y_tr_p1,\n",
    "                        feature_name=['dur','proto','service','state','spkts','dpkts','sbytes','dbytes',\n",
    "                                      'rate','sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt',\n",
    "                                      'sjit','djit','swin','stcpb','dtcpb','dwin','tcprtt','synack','ackdat',\n",
    "                                      'smean','dmean','trans_depth','response_body_len','ct_srv_src',\n",
    "                                      'ct_state_ttl','ct_dst_ltm','ct_src_dport_ltm','ct_dst_sport_ltm',\n",
    "                                      'ct_dst_src_ltm','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd',\n",
    "                                      'ct_src_ltm','ct_srv_dst','is_sm_ips_ports'],\n",
    "                        categorical_feature=['service','state','sttl','dttl','is_ftp_login','ct_ftp_cmd'])\n",
    "\n",
    "lgb_eval = gbm.Dataset(x_tr_p1,y_tr_p1,reference=lgb_train)\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'objective': 'multiclass',\n",
    "    'metric': 'multi_logloss',\n",
    "    'num_class':10,\n",
    "    'learning_rate': 0.03,\n",
    "    'verbose': 0,\n",
    "    'tree_learner': 'voting',\n",
    "}\n",
    "evals={}\n",
    "clf = gbm.train(params,lgb_train,num_boost_round=50,valid_sets=lgb_eval,evals_result=evals,early_stopping_rounds=3)\n",
    "print(\"Training %.2f seconds:\" % ((time() - start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "gbm.plot_importance(clf,figsize=(5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp=clf.feature_importance()\n",
    "name=clf.feature_name()\n",
    "feature_sorted=[]\n",
    "for i in np.argsort(imp):\n",
    "     feature_sorted.append(name[i])\n",
    "feature_sorted.reverse()\n",
    "f_set = feature_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_array = []\n",
    "for a in range(len(f_set)):\n",
    "    d_train=gbm.Dataset(x_tr_p2, label=y_tr_p2)\n",
    "    params = {\n",
    "        'task': 'train',\n",
    "        'objective': 'multiclass',\n",
    "        'metric': 'multi_logloss',\n",
    "        'num_class':10,\n",
    "        'learning_rate': 0.03,\n",
    "        'verbose': 0,\n",
    "        'tree_learner': 'voting',\n",
    "    }\n",
    "    #training the model\n",
    "    clf_2 = gbm.train(params,d_train,50)\n",
    "    y_pred = [np.argmax(line) for line in clf_2.predict(x_tr_p2)]\n",
    "    acc_score = precision_score(y_pred,y_tr_p2,average=None).mean()\n",
    "    acc_array.append(acc_score)\n",
    "    print (\"Top \",len(f_set),\" feature accuracy result:\",acc_score)\n",
    "    x_tr_p2 = x_tr_p2.drop([f_set.pop()],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Max accuracy\",np.max(acc_array),\"with\",42-np.argmax(acc_array),\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc_array.reverse()\n",
    "plt.plot(acc_array)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp=clf.feature_importance()\n",
    "name=clf.feature_name()\n",
    "feature_sorted=[]\n",
    "for i in np.argsort(imp):\n",
    "     feature_sorted.append(name[i])\n",
    "feature_sorted.reverse()\n",
    "f_set = feature_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr_rnn = x_tr#[f_set[:23]]\n",
    "x_ts_rnn = x_ts#[f_set[:23]]\n",
    "y_tr_rnn = y_tr\n",
    "u_list = [0.0,5.0,6.0,7.0]\n",
    "t = TomekLinks(sampling_strategy=u_list,random_state=34)\n",
    "x_tr_rnn, y_tr_rnn = t.fit_resample(x_tr_rnn,y_tr_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "x_tr_rnn = scaler.fit_transform(x_tr_rnn)\n",
    "x_ts_rnn = scaler.transform(x_ts_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREPROCESSING FOR RECURRENT NETWORK\n",
    "x = np.array(x_tr_rnn,dtype=np.float32)\n",
    "y = np.array(y_tr_rnn,dtype=np.int32)\n",
    "max_features = 10\n",
    "y2 = np.zeros((y.shape[0], max_features),dtype=np.float32)\n",
    "y2[np.arange(y.shape[0]), y] = 1.0\n",
    "x = x[:,:,newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ts_rnn = np.array(x_ts_rnn,dtype=np.float32)\n",
    "x_ts_rnn = x_ts_rnn[:,:,newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRUGBM_IDS\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)\n",
    "from tensorflow.keras import regularizers\n",
    "model = Sequential()\n",
    "model.add(CuDNNGRU(120,input_shape=(None,1)))\n",
    "model.add(Dense(10,activation='sigmoid'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'],)\n",
    "#TRAINING\n",
    "start = time()\n",
    "model.fit(x,y2,epochs=10)\n",
    "print(\"Training %.2f seconds:\" % ((time() - start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESTING DATA/WRAPPER FEATURES WITH GRU\n",
    "pred_new = model.predict(x_ts_rnn)\n",
    "pred_new_clas = np.argmax(pred_new,axis=1)\n",
    "acc = accuracy_score(y_ts,pred_new_clas)\n",
    "conf=confusion_matrix(y_ts,pred_new_clas)\n",
    "print (acc)\n",
    "print (conf)\n",
    "print(classification_report(y_ts,pred_new_clas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.725477335665\n",
      "[[28205   555     8   151   797  7067    37    27   152     1]\n",
      " [   96    44   469    12    28     0    16    12     0     0]\n",
      " [   83    46   411    13     9     2     1    12     6     0]\n",
      " [  119   134  2628   557   488    58    29    45    30     1]\n",
      " [  382   194  2773   540  6521   228   158   247    79    10]\n",
      " [ 1713    92   966   158   408  2513    21    51   140     0]\n",
      " [    7    13    34    71   243    44 18434     4    14     7]\n",
      " [   14    12   326    33   267    18     7  2787    31     1]\n",
      " [   15     0     7    18    51    46     4     3   234     0]\n",
      " [    1     0     1     1    16     0     1     0     0    24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.76      0.83     37000\n",
      "           1       0.04      0.06      0.05       677\n",
      "           2       0.05      0.70      0.10       583\n",
      "           3       0.36      0.14      0.20      4089\n",
      "           4       0.74      0.59      0.65     11132\n",
      "           5       0.25      0.41      0.31      6062\n",
      "           6       0.99      0.98      0.98     18871\n",
      "           7       0.87      0.80      0.83      3496\n",
      "           8       0.34      0.62      0.44       378\n",
      "           9       0.55      0.55      0.55        44\n",
      "\n",
      "    accuracy                           0.73     82332\n",
      "   macro avg       0.51      0.56      0.49     82332\n",
      "weighted avg       0.82      0.73      0.76     82332\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#DECISIONTREE / threshold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf3 = DecisionTreeClassifier(random_state=42,class_weight='balanced')\n",
    "x_tr_dt = x_tr\n",
    "x_ts_dt = x_ts\n",
    "clf3.fit(x_tr_dt,y_tr)\n",
    "dt_pred = clf3.predict(x_ts_dt)\n",
    "print (accuracy_score(y_ts,dt_pred))\n",
    "print (confusion_matrix(y_ts,dt_pred))\n",
    "print(classification_report(y_ts,dt_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alper/.local/lib/python3.6/site-packages/ipykernel_launcher.py:10: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.709505417092\n",
      "[[27043   349     8   212  1353  7231     8   759    36     1]\n",
      " [   54    81    93   207   230    10     0     2     0     0]\n",
      " [   23    71    34   194   224    14     0    22     1     0]\n",
      " [  128   496   852   858  1441   162    16   119    17     0]\n",
      " [  579   557   810   990  7201   522     9   429    35     0]\n",
      " [ 1704   184   159   432   692  2737     3   143     8     0]\n",
      " [   41     3     2   103   382   106 18185    36    13     0]\n",
      " [  234    55   110    84   465   360     2  2174    12     0]\n",
      " [   35     0     0     8    33    70     2   130   100     0]\n",
      " [    3     0     0     1    28     5     0     5     0     2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.73      0.81     37000\n",
      "           1       0.05      0.12      0.07       677\n",
      "           2       0.02      0.06      0.03       583\n",
      "           3       0.28      0.21      0.24      4089\n",
      "           4       0.60      0.65      0.62     11132\n",
      "           5       0.24      0.45      0.32      6062\n",
      "           6       1.00      0.96      0.98     18871\n",
      "           7       0.57      0.62      0.59      3496\n",
      "           8       0.45      0.26      0.33       378\n",
      "           9       0.67      0.05      0.09        44\n",
      "\n",
      "    accuracy                           0.71     82332\n",
      "   macro avg       0.48      0.41      0.41     82332\n",
      "weighted avg       0.78      0.71      0.74     82332\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#KNN threshold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "###\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "x_tr_knn = x_tr\n",
    "x_ts_knn = x_ts\n",
    "scaler = StandardScaler()\n",
    "x_tr_knn = scaler.fit_transform(x_tr_knn)\n",
    "x_ts_knn = scaler.transform(x_ts_knn)\n",
    "clf_knn.fit(x_tr_knn,y_tr)\n",
    "knn_pred = clf_knn.predict(x_ts_knn)\n",
    "print (accuracy_score(y_ts,knn_pred))\n",
    "print (confusion_matrix(y_ts,knn_pred))\n",
    "print(classification_report(y_ts,knn_pred))###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alper/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.695719768741\n",
      "[[23067    16     0    31  1824 10490     1  1565     6     0]\n",
      " [   56     2     0     0   592    19     0     8     0     0]\n",
      " [    3     0     0     0   515    25     0    40     0     0]\n",
      " [   51     0     0    55  3506   200    28   243     6     0]\n",
      " [  268     0     0    17  9825   626    12   381     3     0]\n",
      " [  527     0     0     0  1517  3748     1   268     1     0]\n",
      " [   13     0     0     2   475   170 18164    47     0     0]\n",
      " [   16     0     0     0   795   259    27  2399     0     0]\n",
      " [    3     0     0     0    34    93     0   233    15     0]\n",
      " [    1     0     0     0    30     7     0     1     0     5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.62      0.76     37000\n",
      "           1       0.11      0.00      0.01       677\n",
      "           2       0.00      0.00      0.00       583\n",
      "           3       0.52      0.01      0.03      4089\n",
      "           4       0.51      0.88      0.65     11132\n",
      "           5       0.24      0.62      0.35      6062\n",
      "           6       1.00      0.96      0.98     18871\n",
      "           7       0.46      0.69      0.55      3496\n",
      "           8       0.48      0.04      0.07       378\n",
      "           9       1.00      0.11      0.20        44\n",
      "\n",
      "    accuracy                           0.70     82332\n",
      "   macro avg       0.53      0.39      0.36     82332\n",
      "weighted avg       0.80      0.70      0.70     82332\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alper/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#SVM threshold\n",
    "from sklearn import svm\n",
    "clf_svm = svm.SVC(random_state=42)\n",
    "scaler = StandardScaler()\n",
    "x_tr_svm = scaler.fit_transform(x_tr)\n",
    "x_ts_svm = scaler.transform(x_ts)\n",
    "clf_svm.fit(x_tr_svm,y_tr)\n",
    "svm_pred = clf_svm.predict(x_ts_svm)\n",
    "print (accuracy_score(y_ts,svm_pred))\n",
    "print (confusion_matrix(y_ts,svm_pred))\n",
    "print(classification_report(y_ts,svm_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
